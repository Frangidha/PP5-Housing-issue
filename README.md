# Heritage Housing Prediction

Live Site: [Live Site](https://github.com/USERNAME/REPOSITORY/blob/main/README.md)

Link to Repository: [Repository](https://github.com/YourUsername/YourRepository/blob/main/README.md)

## Table of Content

- [Heritage Housing Prediction](#heritage-housing-prediction)
  - [Table of Content](#table-of-content)
  - [Introduction](#introduction)
  - [CRISP-DM Workflow](#crisp-dm-workflow)
    - [Epic 1: Business Understanding](#epic-1-business-understanding)
    - [Epic 2: Data Understanding](#epic-2-data-understanding)
    - [Epic 3: Data Preparation](#epic-3-data-preparation)
    - [Epic 4: Modeling \& Evaluation](#epic-4-modeling--evaluation)
    - [Epic 5: Deployment](#epic-5-deployment)
  - [Business Requirements](#business-requirements)
    - [Project Objectives](#project-objectives)
    - [User Stories](#user-stories)
  - [Dataset Content](#dataset-content)
  - [Mapping the Business Requirements to Data Visualizations and ML Tasks](#mapping-the-business-requirements-to-data-visualizations-and-ml-tasks)
  - [Business Requirement 2](#business-requirement-2)
  - [Business Requirement 3](#business-requirement-3)
  - [Unfixed Bugs](#unfixed-bugs)
  - [PEP8 Compliance Testing](#pep8-compliance-testing)
  - [Deployment](#deployment)
    - [Heroku Deployment](#heroku-deployment)
  - [Technologies](#technologies)
    - [Development and Deployment](#development-and-deployment)
    - [Main Data Analysis and Machine Learning](#main-data-analysis-and-machine-learning)
  - [Credits](#credits)
  - [Media](#media)
  - [Acknowledgements](#acknowledgements)

## Introduction

This Machine Learning Project was developed as the fifth portfolio project during the Code Institute's Diploma in Full Stack Development. It covers the Predictive Analytics specialization.

The Machine Learning, Data Analysis toolkit & neural networks are applied to a real estate dataset with the specific purpose of allowing a user to predict the sale value of a property based on certain features of the home. It also allows the user to see how certain features of a home correlate with the sale price of the home.

## CRISP-DM Workflow

The project was developed using the Cross Industry Standard Process for Data Mining. This follows several iterations over well-defined steps:

### Epic 1: Business Understanding

- This initial phase revolves around comprehending the business problem at hand. It involves defining the objectives of the data mining project, understanding what the business hopes to achieve, and establishing success criteria. In this epic, you aim to align data analysis with the specific goals and requirements of the business.

### Epic 2: Data Understanding

- Once the business objectives are clear, the focus shifts to acquiring the relevant data. This stage involves gathering data from various sources and getting familiar with its structure and quality. Data exploration and initial insights help ensure that the collected data is suitable for analysis.

### Epic 3: Data Preparation

- This epic revolves around the transformation and preparation of the data for modeling. It includes tasks such as data cleaning, feature engineering, and handling missing values. The goal is to create a well-structured dataset that can be used effectively by machine learning algorithms.

### Epic 4: Modeling & Evaluation

- In this stage, the actual modeling takes place. It involves selecting appropriate machine learning algorithms, training models, and assessing their performance. Evaluation metrics are used to determine how well the models align with the business objectives. Iterative experimentation is often part of this phase.

### Epic 5: Deployment

- Once a satisfactory model is built, it needs to be deployed in a real-world context. This phase includes implementing the model into operational systems and continuously monitoring its performance. Ongoing maintenance and retraining are essential to ensure that the model remains effective and aligned with the evolving business goals.
- Develop the Streamlit app that will satisfy the business requirements determined in collaboration with the client and deploy the app online. The app is deployed on Heroku, and the process is described in the Deployment section below.

These steps can be matched up nicely to 6 Epics in the Agile development process. As we move along the pipeline of the development process, we may flow back and forth between stages/epics as we learn new insights and have to revisit previous steps to refine the development while ultimately moving towards the final delivery of a product that satisfies the user's/client's requirements.

## Business Requirements


### Project Objectives


### User Stories



## Dataset Content



## Mapping the Business Requirements to Data Visualizations and ML Tasks

.

## Business Requirement 2



## Business Requirement 3


## Unfixed Bugs




## PEP8 Compliance Testing


## Deployment

### Heroku Deployment




## Technologies

### Development and Deployment


### Main Data Analysis and Machine Learning



- **GradientBoostedRegressor:**

## Credits


## Media

- all images were taken from shutterstock


## Acknowledgements

